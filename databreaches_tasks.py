# -*- coding: utf-8 -*-
"""Databreaches_Tasks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d2kFJAbpDjYfWrjcCDVI3pe0zK1QaRxM
"""

# Import libraries
import pandas as pd
from pandas.core.common import flatten
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import datefinder
import re
from pygrok import Grok
DIMS=(16, 6)

import nltk
nltk.download("stopwords")
nltk.download("words")
from nltk.corpus import stopwords, words

import requests
from bs4 import BeautifulSoup

import re

"""

### Data cleanup
Drop the first row
From 'story' column, extract <Mon YYYY> pattern into another column called 'Month Year'.

### Defining all the methods used
covertToNumber(record)

cleanData(df)

extractAndStripDateFromStory(df)

getWords(storyList)

getUniqueStoryWords(words_unique)
"""

def covertToNumber(record):
    # Remove all commas
    rec = re.sub(',','',record)
    # Convert to float
    num = float(rec)
    return num

# *********************************** #
def cleanData(df):
    # drop the first row
    df.drop([0], axis=0, inplace=True)

    # Drop the columns that are not required
    df.drop(['alternative name', 'interesting story', 'DATA SENSITIVITY',  'DISPLAYED RECORDS', 'Unnamed: 10', '1st source link' , '2nd source link'], axis=1, inplace=True)

    # drop rows that are blank in the columns of interest
    df.dropna(inplace=True)
    # Convert the 'records lost' string to numerical values
    df['records lost'] = df['records lost'].apply(covertToNumber)

# *********************************** #
def extractAndStripDateFromStory(df):
    stories = list(df['story'])
    date_pattern = '%{MONTH:month} %{YEAR:year}'
    p = ''
    month = []
    story = []

    for s in stories:
        grok = Grok(date_pattern)
        d = grok.match(s)
        dt = p.join(d['month'] + " " + d['year'] + ".")
        m = d['month']
        month.append(m)
        st = re.sub(dt, '', s)
        story.append(st)
    df['story'] = story
    df['Month'] = month

# *********************************** #
def getWords(storyList):
    wordsList = []
    s1 = []
    s2 = []
    for s in storyList:
        # Remove any special characters and numbers
        s1 = re.sub('[^a-zA-Z \n]', '', s)
        # Convert to lower case, remove leading and trailing spaces
        s1 = s1.strip().lower()

        # split all the stories into independent words
        s2.append(s1.split())
        wordsList = list(flatten(s2))
    return wordsList

# *********************************** #
def getUniqueStoryWords(words_unique):

    story_words = ''
    sWords = []

    # Remove all stop words described in the nltk stopword list for English
    # convert the list of unique words to pandas dataframe to check for stopwords
    df_words = pd.DataFrame(words_unique)
    df_words.columns = ['Unique Words']
    engStopWords = stopwords.words('english')
    df_story_words = df_words[~df_words['Unique Words'].isin(engStopWords)]

    # Convert the df column to a long string of words
    sWords = df_story_words['Unique Words'].tolist()
    #print(sWords)

    # Create a long string of all words in the list
    for w in sWords:
        #simple string concatenation
        story_words = story_words + ' ' + w

    return story_words

# *********************************** #

df = pd.read_csv('Balloon_Race_Data_Breaches.csv', encoding='latin-1')

# Clean data
cleanData(df)
# Extract Month from story into a column
# Extract only story into story column
extractAndStripDateFromStory(df)

"""### From the cleaned up table, extract requied series for the plots
1. Plot of number of lost records per month per year - plots of different color for different year overlap
2. Plot of number of lost records per sector
3. Word cloud of story
"""

# 1. Plot of number of lost records per year, number of breaches per year
# 2. Plot of number of lost records per sector
yearRange = ['2015', '2016','2017', '2018', '2019']
df_per_year = df.copy()
df_per_year = df_per_year[['records lost', 'YEAR']]

df_per_year = df_per_year.groupby('YEAR').agg({'records lost': ['sum', 'size']})
df_per_year = df_per_year.reset_index()
df_per_year.columns = pd.Index(['Year', 'Total Records Lost', 'Number of Breaches'])

# 2. Plot of number of breaches per sector
df_per_sector = df.copy()
df_per_sector = df_per_sector[['YEAR', 'SECTOR', 'records lost']]
#df_per_sector = df_per_sector.groupby('SECTOR').size()
df_per_sector = df_per_sector.groupby(['YEAR','SECTOR']).size().reset_index(name='Number of breaches')
df_per_sector_5yr = df_per_sector[df_per_sector['YEAR'].isin(yearRange)]

# Create the term_grade_loans_pivot where the index is grade and the columns are the different terms
data_breach_pivot = pd.pivot_table(df_per_sector_5yr, index='SECTOR', columns='YEAR',
                                       values='Number of breaches', aggfunc=np.sum, fill_value = 0)

"""### Method of data breach
Plotting the number of breaches by method of breach
"""

df_method = df.copy()
df_method = df_method.groupby(['METHOD']).size().reset_index(name='No. of Breaches')

df_method.head()

"""#### To plot a word cloud from stories/news about data breach"""

# Extract all the stories into a series and convert it into a list
df_story = df.copy()
storyList = df_story['story'].tolist()

# Replace all special characters with '' and create a long string concatenating all stories
wordsList = getWords(storyList)

onlyWords = getUniqueStoryWords(wordsList)



"""### Plots
Plotting 2 bar plots: breaches per year and number of records lost per year
"""

fig = plt.figure(figsize=(18, 7))

# ax1 - number of breaches per year
# ax2 - number of records lost per year
ax1 = fig.add_subplot(1,2,1)
ax2 = fig.add_subplot(1,2,2)

#Plot number of breaches per year
sns.lineplot(x=df_per_year['Year'], y=df_per_year['Number of Breaches'], ax=ax1
           ,color="tomato", marker='o')
ax1.set_ylabel("No. of breaches")
ax1.set_xlabel("Year")
plt.xticks(rotation='vertical')
ax1.set_title("Number of breaches per year")


# number of records lost per year
blue, = sns.color_palette("muted", 1)
sns.lineplot(x=df_per_year['Year'], y=df_per_year['Total Records Lost'], ax=ax2
           ,color="skyblue", lw = 3)
#ax2.fill_between(df_per_year['Year'], 0, lw, alpha=.3)
ax2.set_title("Total Records Lost per year")
ax2.set_ylabel("No. of records lost")
ax2.set_xlabel("Year")
plt.xticks(rotation=90)


#Show the graph
plt.grid()
plt.show()

"""### Plotting breaches per sector per year
Plotting bar charts - for number of breaches per sector in the past 5 years
"""

DIMS=(16, 6)
fig, ax1 = plt.subplots()

data_breach_pivot.plot(kind='bar', stacked=True,
                                  figsize=DIMS, title="No. of breaches per year for a given sector, from 2014-2019",
                                   ax=ax1)
ax1.set_ylabel("No. of breaches per year per sector")
plt.show()

"""#### Observations:
    Most number of breaches in each of the years between 2015-2019 has been in the web sector.
    2015, 2016 saw lot more breaches in health care and government sectors but the number of breaches in the subsequent years went down
    Most breaches were seen in 2018 and most number of records were also compromised
    The peaks and dips in number of breaches alternate. Perhaps the new security methods get hacked and result in new peaks followed by a dip with more robust security measures (personal observation)

### Method of data breach
Plotting the number of breaches by method of breach

### Plotting a bar graph to indicate the number of breaches against method of breach
"""

DIMS=(16, 6)
fig, ax1 = plt.subplots()

sns.barplot(y=df_method['METHOD'], x=df_method['No. of Breaches'], ax=ax1, color="skyblue")
ax1.set_xlabel('Method of data breach', fontsize=14)
ax1.set_ylabel('Number of data breaches', fontsize=14)
ax1.set_title("No. of breaches versus Method of breach", fontsize=16)
plt.show()

"""### Observations
- Hacking seems to be the most effective or most used method of data breach
- Most number of breaches occurred in 2018
- A fair number of data breaches occurred due to lost/stolen devices
- Followed by poor security as cause of data breach
- oops! (Misc error - human negligence/error) which used to be one of the main reasons for data breach, is still contributing factor but has reduced in number

### Plot a word cloud from stories/news about data breach
"""

plt.figure(figsize=(15,8))
desc_wordcloud = WordCloud(
    width=400, height=150,
    background_color="white",
    max_words=150, relative_scaling = 1.0).generate(onlyWords)
plt.imshow(desc_wordcloud)
plt.axis("off")
plt.title("Wordcloud of data breach stories", fontsize=20)
plt.show()

"""### Create data set based on cryptocurrency breach data
website: https://www.immuniweb.com/blog/top-ten-most-disastrous-cryptocurrency-breaches-in-2018.html
https://resources.infosecinstitute.com/security-vulnerabilities-of-cryptocurrency-exchanges/#gref
"""

# Source 1: Credits at the end of the notebook
url1 = "https://www.immuniweb.com/blog/top-ten-most-disastrous-cryptocurrency-breaches-in-2018.html"
# Use requests.get(url) to send a request to the server and get the contents. Store it in resp
#
resp = requests.get(url1)

soup = BeautifulSoup(resp.text, 'html.parser')

# Extract h3 tags and store in a list

h3_text = []
# extract info from the widgets
h3_tag = soup.find_all('h3')
for t in h3_tag:
    tt = t.text
    tt = re.sub("[0-9]+\.","",tt)
    h3_text.append(tt.strip())
h3_text = h3_text[:10]
print(h3_text)

# Extract the loss value in currency from the text description
def extractLossValueFromString(loss_list):
    lossValue =[]
    num = ''
    den = ''
    n = 0
    for s in loss_list:
        #print(s)
        n = 0
        loss_str = re.sub(',', '', s)
        result = re.search('\d+\.\d+ million|\d+ million',loss_str)
        if (len(result.group()) > 1):
            [num, den] = result.group().split()
        lossValue.append(float(num))

    return(lossValue)

# Extract details from the text part of different tags
def extractDataForDF(p_tag):
    count = 0
    p_new = []
    p_last = []
    full_story = []
    fs = ''

    # Extract the data before the useful information and remove it from the p_tag list
    for p in p_tag:
        if 'When:' in p.text :
            break
        else:
            p_new.append(p)

    for x in p_new:
        p_tag.remove(x)

    # Extract the trailing texts (there are 12 - manually checked) and remove from main p_tag
    tagsToexclude = len(p_tag) - 12
    for i in range(tagsToexclude):
        p_last.append(p_tag[i].text)

    #print("*********************")
    # Seggregate the contents into separate lists
    for p in p_last:
        if 'When:' in p:
            p = re.sub('When:','', p)
            # Extract only month as the entire dataset is for 2018
            p = re.sub('2018.','', p)
            p = re.sub('2018','', p)
            p_when.append(p.strip())

            if (count > 0):
                # Copy the concatenated story here
                fs = ' '.join(full_story)
                p_story.append(fs)
                full_story = []
            count += 1
        elif 'What was lost:' in p:
            p = re.sub('What was lost: ', '', p)
            p_what.append(p.strip())
        elif 'How:' in p:
            p = re.sub('How:', '', p)
            p_how.append(p.strip())
        else:
            full_story.append(p)

    # append the last story
    fs = ' '.join(full_story)
    p_story.append(fs)

# Map breach method with keywords used in the description of methods
def extractBreachMethod(how):
    breachTechniques = ['phishing', 'hack', 'direct theft', 'insider theft', 'security',
                        'blockchain vulnerability', 'compromised wallet', 'cyber intrusion',
                        'employee PC', 'protocol flaw' ]
    breachKeyword = ['phishing', 'hack', 'direct', 'insider', 'security',
                        'blockchain', 'wallet', ' intrusion',
                        'PC', 'protocol' ]
    method = []
    for m in how:
        for t in breachKeyword:
            if t.lower() in m.lower():
                break
        method.append(breachTechniques[breachKeyword.index(t)])
    return (method)

# Extract correcponding p tags
p_story = []
p_when = []
p_what = []
p_how = []

p_tag = soup.find_all('p')

# Extract other useful information from the p tags
extractDataForDF(p_tag)
p_lossValue = extractLossValueFromString(p_what)
p_method = extractBreachMethod(p_how)

# Create a dataframe from all the extracted data
superList = []
superList = list(zip(h3_text, p_when, p_what, p_lossValue, p_how, p_method, p_story))
df_crypto = pd.DataFrame(superList, columns = ['Entity', 'When' , 'Loss', 'Loss Value in $', 'Method description', 'Method', 'Story'])
# Write the data to a csv file
df_crypto.to_csv('cryptoBreach2018.csv', index=False, sep = '|')

# For plotting
df_new = df_crypto[['Method', 'Loss Value in $']]
df_new = df_new.groupby('Method')['Loss Value in $'].sum()
df_new = df_new.reset_index()
df_new.columns = pd.Index(['Method','Total Loss in million $'])

fig, ax3 = plt.subplots()
sns.barplot(y=df_new['Method'], x=df_new['Total Loss in million $'], ax=ax3, color="skyblue")
ax3.set_xlabel('Method of crypto breach', fontsize=14)
#plt.xticks(rotation=90)
ax3.set_ylabel('Loss in $', fontsize=14)
ax3.set_title("No. of crypto currency breaches versus Method of breach in 2018", fontsize=16)
plt.show()

# Extract all the stories into a series and convert it into a list
df_crypto_story = df_crypto.copy()
storyList = df_crypto_story['Story'].tolist()

# Replace all special characters with '' and create a long string concatenating all stories
wordsList = getWords(storyList)

onlyWords = getUniqueStoryWords(wordsList)

plt.figure(figsize=(15,8))
desc_wordcloud = WordCloud(
    width=400, height=150,
    background_color="white",
    max_words=150, relative_scaling = 1.0).generate(onlyWords)
plt.imshow(desc_wordcloud)
plt.axis("off")
plt.title("Wordcloud of Cryptocurrency breach stories", fontsize=20)
plt.show()



"""# APPENDIX
Sources:
Datasets: kaggle
Blogs:
https://resources.infosecinstitute.com/security-vulnerabilities-of-cryptocurrency-exchanges/#gref
https://www.wired.com/story/hack-binance-cryptocurrency-exchange/
"""
